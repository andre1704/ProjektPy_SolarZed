{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projekt SolarZed - zaawansowana eksploracja danych \n",
    "### autor: Andrzej Słowiński\n",
    "### data: 21.01.2019\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp\n",
    "Celem proejktu była predykcja ilości energii wyprodukowanej przez panele słoneczne, na podstawie danych treningowych oraz testowych. Z uwagi na typ danych który był na wejściu oraz wyjściu jest to zadanie gdzie należało rozważać regresję. Trenując algorytm oraz szukając najlepszego rozwiązania sprawdzany jest rmse dla regresji liniowej, oraz dla różnych wartości estymatora w RandomForestRegressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteki oraz wczytanie danych\n",
    "Dane zostały wczytane przy pomocy biblioteki pandas, z pakietu sklearn dla modelu użyte zostały biblioteki LinearRegression, RandomForestRegressor, obliczanie rmse użyta została biblioteka mean_squared_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('Data/train.csv',sep=',')\n",
    "test = pd.read_csv('Data/test.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie danych\n",
    "Dane treningowe oraz testowe zostały przeze mnie sprawdzone czy nie zawierają wartyości pustych, z uwagi że nie było takich wartości nie wymagana była obróbka danych pod kątem wartości pustych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "idsito                  0\n",
       "idmodel                 0\n",
       "idbrand                 0\n",
       "lat                     0\n",
       "lon                     0\n",
       "ageinmonths             0\n",
       "anno                    0\n",
       "day                     0\n",
       "ora                     0\n",
       "data                    0\n",
       "temperatura_ambiente    0\n",
       "irradiamento            0\n",
       "pressure                0\n",
       "windspeed               0\n",
       "humidity                0\n",
       "icon                    0\n",
       "dewpoint                0\n",
       "windbearing             0\n",
       "cloudcover              0\n",
       "tempi                   0\n",
       "irri                    0\n",
       "pressurei               0\n",
       "windspeedi              0\n",
       "humidityi               0\n",
       "dewpointi               0\n",
       "windbearingi            0\n",
       "cloudcoveri             0\n",
       "dist                    0\n",
       "altitude                0\n",
       "azimuth                 0\n",
       "altitudei               0\n",
       "azimuthi                0\n",
       "pcnm1                   0\n",
       "pcnm2                   0\n",
       "pcnm3                   0\n",
       "pcnm4                   0\n",
       "pcnm5                   0\n",
       "pcnm6                   0\n",
       "pcnm7                   0\n",
       "pcnm8                   0\n",
       "pcnm9                   0\n",
       "pcnm10                  0\n",
       "pcnm11                  0\n",
       "pcnm12                  0\n",
       "pcnm13                  0\n",
       "pcnm14                  0\n",
       "pcnm15                  0\n",
       "irr_pvgis_mod           0\n",
       "irri_pvgis_mod          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obróbka danych wejściowych\n",
    "W danych wejściowych znajdowała się kolumna z datą której format uniemożliwaiłby predykcję, dlatego też tworząc funkcję splitDate dane zostały odpowidenio podzielone na kolejne lata, miesiące, dni, godziny.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDate(x, date_part):\n",
    "    if(date_part == \"year\"):\n",
    "        y = datetime.strptime(x, '%m/%d/%Y %H:%M').year\n",
    "    elif(date_part == \"month\"):\n",
    "        y = datetime.strptime(x, '%m/%d/%Y %H:%M').month\n",
    "    elif(date_part == \"day\"):\n",
    "        y = datetime.strptime(x, '%m/%d/%Y %H:%M').day\n",
    "    elif(date_part == \"hour\"):\n",
    "        y = datetime.strptime(x, '%m/%d/%Y %H:%M').hour\n",
    "    return int(y)\n",
    "\n",
    "train['year']= train['data'].apply(lambda x: splitDate(x, \"year\"))\n",
    "train['month']= train['data'].apply(lambda x: splitDate(x, \"month\"))\n",
    "train['day_']= train['data'].apply(lambda x: splitDate(x, \"day\"))\n",
    "train['hour']= train['data'].apply(lambda x: splitDate(x, \"hour\"))\n",
    "\n",
    "test['year']= test['data'].apply(lambda x: splitDate(x, \"year\"))\n",
    "test['month']= test['data'].apply(lambda x: splitDate(x, \"month\"))\n",
    "test['day_']= test['data'].apply(lambda x: splitDate(x, \"day\"))\n",
    "test['hour']= test['data'].apply(lambda x: splitDate(x, \"hour\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W danych treningowych pojawiała się kolumna która była wartością energii paneli słonecznyhch co było wartością wyjściową, dlatego też kolumna ta została przypisana do nowej zmiennej a z danych treningowych usunięta tak jak i stara nie przetworzona kolumna daty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "X_train = X_train.drop(\"kwh\",1)\n",
    "X_train = X_train.drop(\"data\",1)\n",
    "y_train = train.loc[:,'kwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(\"data\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dane testowe i treningowe powtórny podział\n",
    "Z uwagi na to, że musiałem stwierdzić czy dany algorytm predykcji będzie odpowiedni a jednym z sposobów na to jest rmse gdzie potrzebne są dane prawdziwe oraz dane predykowane z danego zbioru testowego podzieliłem zbiór traningowy na podziobry testowe oraz treningowe (X1_train, X1_test, y1_train, y1_test) dzięki czemu mogłem trenować model i badać czy wartość rmse jest dobra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresja, uczenie modelu\n",
    "Projekt obejował wykorzystanie regresji, testowałem w tym zakresie regresję liniową, niestety napotkałem na problem ujemnych wartości które uzyskiwałem po zastosowaniu predykcji, wartość energii nie mogła być ujemna dlatego też przypisałem do wszystkich wartości wyjściowych 0 w przypadku wartości poniżej 0. Po tej operacji wyliczona została wartość rmse dla regresji liniowej.\n",
    "Z napotkanym problemem wartości ujemnycfh poradził sobie model RandomForestRegressor który wymagał jednak jako wartości początkowych informacji o wartości estymatora, dlatego też zbadałem kolejno dla 10 , 50 , 100  czy błąd rmse będzie dla predykowanych danych się poprawiał.\n",
    "Uzyskane dane rmse oraz coeficient zostały zapisane do tabeli array_coef_squared_error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroAssign(x):\n",
    "    if(x>=0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "array_coef_squared_error = []\n",
    "tab_estimators = [10 , 50, 100]\n",
    "\n",
    "reg = LinearRegression(copy_X=True, fit_intercept=True, normalize=True).fit(X1_train, y1_train)\n",
    "y_pred = reg.predict(X1_test)\n",
    "pred_d = {'Id': X1_test['id'] , 'Predicted': y_pred}\n",
    "predicted_data = pd.DataFrame(data=pred_d)\n",
    "predicted_data['Predicted'] = predicted_data['Predicted'].apply(lambda x: zeroAssign(x))  \n",
    "array_coef_squared_error.append([\"linear regression\",reg.score(X1_test, y1_test), mean_squared_error(y1_test,predicted_data['Predicted'])])\n",
    "\n",
    "\n",
    "for i in tab_estimators:\n",
    "    reg = RandomForestRegressor(max_depth=14,n_estimators=i).fit(X1_train, y1_train)\n",
    "    \n",
    "    y_pred = reg.predict(X1_test)\n",
    "    name = \"random forest\"+str(i)\n",
    "    coef = reg.score(X1_train, y1_train)\n",
    "    rmse = mean_squared_error(y1_test,y_pred)\n",
    "    array_coef_squared_error.append([name,coef,rmse])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabela podsumowująca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nazwa algorytmu  coefficient       rmse\n",
      "0  linear regression      0.810993  0.008046\n",
      "1    random forest10      0.963922  0.002872\n",
      "2    random forest50      0.966571  0.002705\n",
      "3   random forest100      0.966864  0.002707\n"
     ]
    }
   ],
   "source": [
    "from astropy.table import Table, Column\n",
    "summary = pd.DataFrame(array_coef_squared_error)\n",
    "summary.columns=['nazwa algorytmu','coefficient ','rmse']\n",
    "                     \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predykcja danych\n",
    "Dane testowe zostały wykorzystane po nauczeniu modelu do wygenerowania predykowanych danych oraz ich zapisania do pliku csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)\n",
    "pred_d = {'Id': X_test['id'] , 'Predicted': y_pred}\n",
    "predicted_data = pd.DataFrame(data=pred_d)  \n",
    "predicted_data['Predicted'] = predicted_data['Predicted'].apply(lambda x: zeroAssign(x))\n",
    "predicted_data.to_csv('Data/submission.csv',sep=',' ,index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "W przypadku RandomForestRegressor testowałem różne wartości n_estimators ostatecznie, wartości rmse nie poprawiały się wystarczającą aby dalej wartość tą zwiększać. W przypadku parametru max_depth dobrany on został ręcznie, po kilku próbach przy coraz większych jego wartościach czas tworzenia modelu wydłużał się dlatego wybrana została największa wartość którą udało się przetestować."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
